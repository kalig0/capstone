# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QiHqtUbYXHJ8ZvCPyaDcEYYMM3QeLrVi
"""

# DATA CLEANING-LOG TRANFORMATION OR SCALING
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Setup visualization
plt.style.use('seaborn-v0_8')
sns.set_theme(style="whitegrid")

def save_file(df, filename):
    """Quick save DataFrame to CSV"""
    df.to_csv(filename, index=False)
    print(f"Saved: {filename}")

# Load and validate data
try:
    df = pd.read_csv('cleaned_tourism_data.csv')[['tourism_arrivals', 'tourism_expenditures', 'gdp']]
    print(f"\nData loaded: {len(df)} rows\nMissing values:\n{df.isnull().sum()}")
except FileNotFoundError:
    raise FileNotFoundError("Data file not found")

# Log transform with auto-shift for non-positive values
print("\nApplying log transforms:")
for col in df.columns:
    shift = abs(min(0, df[col].min())) + 1  # Auto-calculate required shift
    df[f'log_{col}'] = np.log1p(df[col] + shift * (df[col].min() <= 0))
    print(f"{col}: shift={shift if df[col].min()<=0 else 0}")

# Train-test split (80-20) on log-transformed data
X = df[['log_tourism_arrivals', 'log_tourism_expenditures']]
y = df['log_gdp']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standard scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Save processed data
save_file(df, 'log_transformed_data.csv')
pd.DataFrame(X_train_scaled, columns=X.columns).to_csv('X_train_scaled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=X.columns).to_csv('X_test_scaled.csv', index=False)
y_train.to_frame().to_csv('y_train.csv', index=False)
y_test.to_frame().to_csv('y_test.csv', index=False)

# Visualize relationships
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
sns.scatterplot(x='log_tourism_arrivals', y='log_gdp', data=df, ax=ax1).set_title('Arrivals vs GDP')
sns.scatterplot(x='log_tourism_expenditures', y='log_gdp', data=df, ax=ax2).set_title('Expenditures vs GDP')
plt.tight_layout()
plt.savefig('feature_relationships.png')
plt.close()

print(f"\nProcessing complete!\nTraining: {len(X_train)} samples\nTesting: {len(X_test)} samples")

# Random Forest Regression on tourism-GDP data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load preprocessed data
X_train = pd.read_csv('X_train_scaled.csv')
X_test = pd.read_csv('X_test_scaled.csv')
y_train = pd.read_csv('y_train.csv').values.ravel()
y_test = pd.read_csv('y_test.csv').values.ravel()

# Initialize and train Random Forest
rf_model = RandomForestRegressor(
    n_estimators=100,  # Number of trees
    max_depth=None,    # Let trees grow fully
    random_state=42,   # For reproducibility
    n_jobs=-1          # Use all CPU cores
)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Calculate MAPE (Mean Absolute Percentage Error)
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Convert to percentage

mape = mean_absolute_percentage_error(y_test, y_pred)

# Print performance metrics
print("\nRandom Forest Performance:")
print(f"- MAE: {mae:.4f}")
print(f"- RMSE: {rmse:.4f}")
print(f"- MAPE: {mape:.2f}%")
print(f"- R² Score: {r2:.4f}")

# Feature importance analysis
importances = rf_model.feature_importances_
features = X_train.columns
print("\nFeature Importances:")
for feature, importance in sorted(zip(features, importances), key=lambda x: x[1], reverse=True):
    print(f"{feature}: {importance:.3f}")

# Visualize predictions vs actual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.xlabel('Actual log(GDP)')
plt.ylabel('Predicted log(GDP)')
plt.title('Random Forest: Actual vs Predicted')
plt.savefig('rf_predictions.png')
plt.show()

# SVM Regression on tourism-GDP data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler

# Load preprocessed data
X_train = pd.read_csv('X_train_scaled.csv')
X_test = pd.read_csv('X_test_scaled.csv')
y_train = pd.read_csv('y_train.csv').values.ravel()
y_test = pd.read_csv('y_test.csv').values.ravel()

# Initialize and train SVM
svm_model = SVR(
    kernel='rbf',       # Radial Basis Function kernel
    C=1.0,              # Regularization parameter
    epsilon=0.1,        # Epsilon in epsilon-SVR model
    gamma='scale'       # Kernel coefficient
)
svm_model.fit(X_train, y_train)

# Make predictions
y_pred = svm_model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Calculate MAPE (Mean Absolute Percentage Error)
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Convert to percentage

mape = mean_absolute_percentage_error(y_test, y_pred)

# Print performance metrics
print("\nSVM Performance:")
print(f"- MAE: {mae:.4f}")
print(f"- RMSE: {rmse:.4f}")
print(f"- MAPE: {mape:.2f}%")
print(f"- R² Score: {r2:.4f}")

# Visualize predictions vs actual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.xlabel('Actual log(GDP)')
plt.ylabel('Predicted log(GDP)')
plt.title('SVM: Actual vs Predicted')
plt.savefig('svm_predictions.png')
plt.show()